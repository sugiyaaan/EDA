---
title: "EDA assignment 7"
author: "Motoki Sugino"
date: "11/9/2016"
output: html_document
---


###1.Find a two-way table that you are interested in with at least 4 rows and 4 columns.  Analyze the table using both additive AND multiplicative fits.  Plot the additive fit.  Explain your additive and multiplicative fits (what do the common, row effects, and column effects mean).  Is an additive or multiplicative fit more suitable for your data?  Explain.
 
Data source: http://www.usclimatedata.com/

Description: I am interested in finding the average low temperature difference between cities in the USA where I used to live.I made a dataset about Average low temperature in °F.

For additive fits
```{r}
library(LearnEDA)
temperatures <- read.csv("https://docs.google.com/spreadsheets/d/1H_7wX_k7-zC1qBaUDYd3CG05PQPeowMFylAlyyiZoJU/pub?output=csv")
head(temperatures)
temps <- temperatures[, -1]
dimnames(temps)[[1]] <- temperatures[, 1]
additive.fit <- medpolish(temps)
medpolish(temps)
```

Interpreting the row and column effects

An additive model is : $FIT =OverallTemperature+CityEffect+MonthEffect$

Showling row effects, and column effects

*City Month* |January     |April       |July        |October     |REFF        
-------      |-------     |-------     |-------     |-------     |-------
Bowling Green|            |            |            |            |-5.125         
Atlanta      |            |            |            |            |9.875            
Boston       |            |            |            |            |-0.25            
Cookeville   |            |            |            |            |0.250            
CEFF         |-19.9375    |-1.6250     |21.8750     |1.5000      |43.125    



*City Month* |January    |April       |July        |October     |RFIT        
-------      |-------     |-------     |-------     |-------     |-------
Bowling Green|            |            |            |            |38        
Atlanta      |            |            |            |            |53            
Boston       |            |            |            |            |42.875            
Cookeville   |            |            |            |            |43.375            
CEFF         |-19.9375    |-1.6250     |21.8750     |1.5000      |43.125 

So the temperature of Bowling Green in January is represented as

Bowling Green fit + January effect = 38 - 19.9375 = 18.0625. 

This is very interesting to me because Bowling Green is 18.0625 - 3.1875 = 14.875 degree warmer on average in January in this dataset.

And the temperature of Boston in October is fitted by

Boston fit + October effect = 42.875 + 1.5 = 44.375 which is very close to the average degree (44.625) in October.

$FIT =[ COMMON + ROWEFFECT ] + COLEFFECT = ROW FIT + COL EFFECT$

*City Month* |January     |April       |July        |October     |RFIT        
-------      |-------     |-------     |-------     |-------     |-------
Bowling Green|            |            |            |            |38        
Atlanta      |            |            |            |            |53            
Boston       |            |            |            |            |42.875            
Cookeville   |            |            |            |            |43.375            
CFIT         |3.1875      |41.5        |65          |44.625      |    


Looking at this table, specifically the row fits, we see that :

・the average low temperature in Bowling Green, Atlant, Boston and Cookville are 38, 53, 42.875 and 43.375 degrees   respectively. 

・generally, Bowling Green is 42.875 - 38 = 4.875 colder than boston.(To me, this is very interesting because    boston is located to north from Bowling Green)

・Atlanta tends to be 9.625 degrees warmer than Cookeville. (So Atlanta is the warmest place in where I ever      lived)


And specifically the column fits, we see that :

・the Low temperature in Janually, April, July and October are on average 3.1875, 41.5, 65 and 44.625 degrees    respectively.

・it tends to be 41.5 - 3.1875 = 38.3125 degrees warmer in April than January.

・October and April have similar temps on average – October is 3 degrees warmer.(This is very intersting         because it is exactly the same results as the one in Dr Albert's classnotes)


Plotting the two terms of the additive fit
```{r}
Row.Part <- with(additive.fit, row + overall)
Col.Part <- additive.fit$col 
plot2way(Row.Part, Col.Part,
         dimnames(temps)[[1]], 
         dimnames(temps)[[2]])
```

First, note that the highest intersection corresponds to the temperature of Atlanta in July.(This results exactly the same as Dr Albert's classnotes) According to the additive fit, Atlanta city in July is the most warmest place in this datasets. Conversely, Bowling Green in January is the coldest spot – this intersection has the smallest value of fit.

Second, Boston in October and Cookeville in April have similar values of fit. This is interesting because Boton and Cookevill (in TN) is not close to each other location wise. 

Third, we can see that the rectangular region is just slightly rotated off the vertical so the more critical dimension of fit is the time of the year.


Looking at the residuals
```{r}
#Adding information about the residuals to the display
additive.fit$residual
aplpack::stem.leaf(c(additive.fit$residual), unit=1, m=5)
```

Most of the residuals are small – between -1 and 1. The large residuals  ane -3.0625 (Bowling Green, January) and 2.625 (Boston, October).
Roughly, January has a large deviation between cities.

For multiplicative fits
```{r}
temps <- temperatures[, -1] 
row.names(temps) <- temperatures[, 1] 
temps
```

What patterns do we see in this table?
Actually, the temperatures increase January to July and after that they decrese. There is no relationship between the columns of the table is multiplicative, rather than additive.
So in this case, a multiplicative model seems not to be suitable.

```{r}
#Fitting our model to the data
log.temps <- log10(temps)
log.temps

additive.fit <- medpolish(log.temps)

options(width=60) 
additive.fit
```

To demonstrate the fit, note that the log temperatures for Bowling Green in January is 1.176091 We can express this log temperatures as

1.176091 = 1.634877 - 0.055696207 - 0.25617944 - 0.146911

where

・ 1.634877 is the common value

・- 0.055696207 is the additive effect due to the Bowling green

・− 0.25617944 is the additive effect due to January

・− 0.146911 is the residual (what’s left of the data after taking out the additive fit)


To get a fit for the original temperature data, we take the common, row effects, column effects, and residuals each to the 10th power.
```{r}
COMMON <- 10 ^ additive.fit$overall
ROW <- 10 ^ additive.fit$row
COL <- 10 ^ additive.fit$col
RESIDUAL <- 10 ^ additive.fit$residual
COMMON
ROW
COL
RESIDUAL
```

Interpreting the fit

*City Month* |January     |April       |July        |October     |REFF        
-------      |-------     |-------     |-------     |-------     |-------
Bowling Green|            |            |            |            |0.8796376         
Atlanta      |            |            |            |            |1.2283471            
Boston       |            |            |            |            |0.9939937            
Cookeville   |            |            |            |            |1.0060426            
CEFF         |0.5543966   |0.9619204   |1.5067316   |1.0364228   |43.13973   


To get fitted temperature for each month, we multiply the row effects (reff) by the common value to get the following table.


*City Month* |January     |April       |July        |October     |RFIT     |Additive RFIT 
-------      |-------     |-------     |-------     |-------     |-------  |---------
Bowling Green|            |            |            |            |37.94733 |(38)        
Atlanta      |            |            |            |            |52.99056 |(53)            
Boston       |            |            |            |            |42.88062 |(42.875)            
Cookeville   |            |            |            |            |43.4004  |(43.375)            
CEFF         |0.5543966   |0.9619204   |1.5067316   |1.0364228   |43.13973 |43.125


To compare temperature in the cities, then we look at ratios.
For example, comparing Bowling Green and Boston, the ratio of the corresponding row fits is  37.94733/42.88062 = 0.8849529. So we can say that temperature in Bowling Green were on the average about 11% (1-0.8849529) colder than Boston.

Likewise, we can see the effects of the different distances.

*City Month*          |January     |April       |July        |October    
-------               |-------     |-------     |-------     |-------     
Column Effect         |0.5543966   |0.9619204   |1.5067316   |1.0364228   
Effect / Effect (Jan) |1           |1.735076    |2.717787    |1.869461

From the table above, we can see that the July temperature is 2.717787 times as long as the January temperature. But the October temperature is 1.869461 times as long as the January temperature. So we can see the decrease from July to October. 

To gain a better understanding of the row and column effects with plots.
```{r}
#par(mfrow=c(2, 1))
#plot(city, additive.fit$row,
#     xlab="1=BowlingGreen, 2=Atlanta, 3=Boston, 4=Cookville",
#     ylab="Row Effect", pch=19,type="p",legend.text = NULL,
#main="Plot of Year Effects") 
city <- c(1,2,3,4)
x <- factor(city, labels = c("BowlingGreen", "Atlanta", "Boston", "Cookville"))
require(ggplot2)
p <- qplot(x, additive.fit$row)+
  labs(title="Plot of City Effects",
       x="City", y = "Row Effect")
p
```

From this table above, we can see that Alanta has highest Row effect. Namely, the Atlant get warmer than any other cities in this datasets.


```{r}
month <- c(1,4,7,10)
month.1 <- log10(month)
plot(month.1, additive.fit$col,
     ylab="Col Effect", pch=19,type="p",
     xlab="Log Month",
     main="Plot of Month Effects")

```

We can see that Log month increase from 0.0 (January) to 0.8 (July) and decrese from 0.8 (July) to 1.0 (October).

Interpreting the residuals
```{r}
round(RESIDUAL, 2)
```

The smallest residual is 0.71 (Bowling Green, January).
The largest residual is 1.16 (Atlanta, January).


In conclusion, an additive fit is more suitable for your data to me since there is no multiplicative relationship between cities.








###2.Fit a multiplicative fit to ONE of these two datasets:  

I am going to choose the dataset,olympics.speed.skating. 

olympics.speed.skating

This datasets give the Olympics winning time in the men’s speed skating as a function of the year and length of race.

For multiplicative fits
```{r}
head(olympics.speed.skating)
times <- olympics.speed.skating[, -1] 
row.names(times) <- olympics.speed.skating[, 1] 
times
```

What patterns do we see in this table?

Certainly, we can see the times to get larger for the longer distances. Also, we see some decrease in the winning times as a function of year. There are improvements in training and skating technique that can lead to better race times.

So, in this case, An multiplicative model is more suitable.

```{r}
#Fitting our model to the data
log.times <- log10(times)
log.times

additive.fit <- medpolish(log.times)

options(width=60) 
additive.fit
```

To demonstrate the fit, note that the log time for the 500 m race in 1976 is 1.592954. 

We can express this log temperatures as

1.592954 = 2.049451 + 0.029706154 - 0.4839780 - 0.0022252

where

・ 2.049451 is the common value

・ 0.029706154 is the additive effect due to the Bowling green

・- 0.4839780 is the additive effect due to January

・− 0.0022252 is the residual (what’s left of the data after taking out the additive fit)


To get a fit for the original time data, we take the common, row effects, column effects, and residuals each to the 10th power.
```{r}
COMMON <- 10 ^ additive.fit$overall
ROW <- 10 ^ additive.fit$row
COL <- 10 ^ additive.fit$col
RESIDUAL <- 10 ^ additive.fit$residual
COMMON
ROW
COL
RESIDUAL
```

Interpreting the fit

*year meter* |500m        |1000m       |1500m       |5000m       |10000m      |REFF        
-------      |-------     |-------     |-------     |-------     |-------     |-------
1976         |            |            |            |            |            |1.0707946       
1980         |            |            |            |            |            |1.0343171         
1984         |            |            |            |            |            |1.0562199         
1988         |            |            |            |            |            |1.0000000         
1992         |            |            |            |            |            |1.0245404         
1994         |            |            |            |            |            |0.9880815        
1998         |            |            |            |            |            |0.9626093         
2002         |            |            |            |            |            |0.9276281         
2006         |            |            |            |            |            |0.9433110       
CEFF         |0.3281119   |0.6517044   |1.0000000   |3.6108335   |7.4220016   |112.06


To get fitted time for each year, we multiply the row effects (reff) by the common value to get the following table.


*year meter* |500m        |1000m       |1500m       |5000m       |10000m      |RFIT        
-------      |-------     |-------     |-------     |-------     |-------     |-------
1976         |            |            |            |            |            |119.9932       
1980         |            |            |            |            |            |115.9056         
1984         |            |            |            |            |            |118.36  
1988         |            |            |            |            |            |112.06      
1992         |            |            |            |            |            |114.81         
1994         |            |            |            |            |            |110.7244         
1998         |            |            |            |            |            |107.87         
2002         |            |            |            |            |            |103.95         
2006         |            |            |            |            |            |105.7074       
CEFF         |0.3281119   |0.6517044   |1.0000000   |3.6108335   |7.4220016   |   


To compare years, then we look at ratios.
For example, comparing 1976 and 2006, the ratio of the corresponding row fits is 119.9932/105.7074 = 1.135145. So we can say that times in 1976 were on the average about 14% slower than they were in the year 2006.

Likewise, we can see the effects of the different distances.

*meter*                |500m        |1000m       |1500m       |5000m       |10000m  
-------                |-------     |-------     |-------     |-------     |-------  
Column Effect          |0.3281119   |0.6517044   |1.0000000   |3.6108335   |7.4220016
Effect / Effect (500m) |1           |1.986226    |3.047741    |11.00488    |22.62034  

From the table above, we can see that the July temperature is 2.717787 times as long as the January temperature. But the October temperature is 1.869461 times as long as the January temperature. So we can see the decrease from July to October. 

The 1000m time is barely twice as long as the 500m. The 1500m time is barely third time as long as the 500m.
However, the 10000m time is 22.6 times as long as the 500m time. 
So we can slightly see a fatigue effect.


To gain a better understanding of the row and column effects with plots.
```{r}
Year <- c(1976, 1980, 1984, 1988, 1992, 1994, 1998, 2002, 2006)
Log.Distance <- log10(c(500, 1000, 1500, 5000, 10000)) 
par(mfrow=c(2, 1))
plot(Year, additive.fit$row,
     ylab="Row Effect", pch=19,
main="Plot of Year Effects")

plot(Log.Distance, additive.fit$col,
     ylab="Col Effect", pch=19,
     xlab="Log Distance",
     main="Plot of Distance Effects")
```

From the graphs, we see

・There was general decrease in log time from 1976 to 2005 but 1984, 1992 and 2006 increased a little bit from previous year.

・Year 2002 has the short times in this datasets.

・The log times increase linearly as a function of log distance. However,this graph doesn’t show the fatigue effect. 


Interpreting the residuals
```{r}
round(RESIDUAL, 2)
```


Generally, the residuals are between 0.98 and 1.01.
There is the largest residual in 5000m in year 1976. 






###3.For the following data, analyze using an extended fit.  Interpret the fit and the residuals.
Response:  average (median) attendance of worship at Norcrest church,Findlay,OH classified by month and year.
Dataset:  church.2way


```{r}
attendance <- church.2way[, -1] 
row.names(attendance) <- church.2way[, 1] 
attendance
```

To show the an additive model using median polish.
```{r}
(additive.fit <- medpolish(attendance))
```

From this table above, it will be helpful to order the rows and columns of the table by the effects.
Actually, the columns are already ordered by effects, however, the row are not.

```{r}
attendance <- attendance[order(additive.fit$row), ]
(additive.fit <- medpolish(attendance))
```

Now both row and column effects are ordered.

Interpret the fit.
From Row Effects, there was the lowest attendance in July (370.5156 - 59.734375 = 310.7812) and there was the highest attendance in November (370.5156 + 27.015625 = 397.5312). 

From Column Effects, we can see that attendance was incresing every year. 
The lowest attendance is 325.2187 in year 1993 and the highest one is 396.0937 in year 1996.

Looking at residuals
```{r}
additive.fit$residual
```

table |    y1993  |    y1994  |   y1995   | y1996     |REFF       |sign
----- |-----      |-----      |-----      |-----      |-----      |-----
July  |-0.484375  |3.359375   |-5.50000   |1.640625   |-59.734375 |*-*
Aug   |20.265625  |-20.890625 |14.25000   |-16.609375 |-44.484375 |*-*
June  | 0.484375  |9.328125   |-10.53125  |-0.390625  |-20.703125 |*-*
Feb   |-17.734375 |15.109375  |-3.75000   |1.390625   |-12.484375 |*-*
Jan   |12.984375  |-29.171875 |21.96875   |-12.890625 |-2.203125  |*-*
Sept  |-35.203125 |-26.359375 |26.78125   |34.921875  |-2.015625  |*-*
May   |-4.234375  |30.609375  |2.75000    |-5.109375  |2.015625   |*+*
Mar   |-24.234375 |21.609375  |-17.25000  |14.890625  |7.015625   |*+*
Oct   |8.484375   |-28.671875 |16.46875   |-8.390625  |11.296875  |*+*
Apr   |-20.734375 |37.109375  |-2.75000   |0.390625   |16.515625  |*+*
Dec   |29.796875  |-3.359375  |3.78125    |-38.078125 |22.984375  |*+*
Nov   |52.765625  |-17.390625 |-3.25000   |0.890625   |27.015625  |*+*
CEFF  |-45.296875 |-4.140625  |3.718750   |25.578125  |           |
sign  |*-*        |*-*        |*+*        |*+*        |           |


There is large residual which is 52.765625 (Nov,y1993).
The smallest residual is -38.078125 (Dec,y1996).

Both results are interesting because the column effects in year 1993 is the lowest but there is the largest deviation in residual in year 1993. On the other hand, year 1996 has the largest column effects (25.578125), however the lowest residual (-38.078125) is in year 1996.

Therefore, we could say that there was a very clear pattern in the residuals.




Comparison values

$cv = ROWEFF × COLEFF / COMMON$ 


Extending the additive model by one more term

This new model callesd extended model.

$FIT = COMMON +ROW EFF +COLEFF +kCV$

Finding k
```{r}
cv <- with(additive.fit,
           outer(row, col, "*") / overall)
plot(as.vector(cv), as.vector(additive.fit$residuals), 
    xlab = "COMPARISON VALUES", ylab = "RESIDUALS")
rline(as.vector(cv), as.vector(additive.fit$residuals))$b
# We check the suitability of our line fit by looking at the residuals and seeing if we have removed the trend from the scatterplot. (It appears from the graph that we have indeed removed the trend from the plot.)

plot(as.vector(cv),
as.vector(additive.fit$residuals) - 1.460397* as.vector(cv), xlab = "COMPARISON VALUES", ylab = "RESIDUAL FROM FIT", main="Checking Suitability of Line Fit")
abline(h=0, col="red")
```

The slope of this line, 1.460397, is our estimate at the coefficient k. So our improved fit to these data has the form

$FIT = COMMON +ROW EFF +COLEFF +1.460397CV$


If k is not close to 1, then the recommendation is to perform an additive fit to transformed data where the data is reexpressed using a power transformation with power p = 1 − k. Therefore p = 1 - 1.460397 = -0.460397

Extended fits and transformations
```{r}
attendance <- church.2way[, -1]
attendance <- attendance^(-0.46)
dimnames(attendance)[[1]] <- church.2way[, 1]
additive.fit <- medpolish(attendance)
medpolish(attendance)
```

Interpret the fit.
From Row Effects, the $attendance^{(-0.46)}$ in July is 0.07149842 (0.06542966 + 6.068761e-03).

The $attendance^{(-0.46)}$ in November 0.06378561 (0.06542966-1.644051e-03). 

From Column Effects, y1993, y1994 ,y1995 and y1996  are (0.0047123570,  0.0002541476, -0.0001503402, -0.0018977819) respectively.

```{r}
plot(as.vector(cv), as.vector(additive.fit$residuals), 
    xlab = "COMPARISON VALUES", ylab = "RESIDUALS")
```

The residuals are transformed within smaller range. 

Plotting the two terms of the additive fit
```{r}
Row.Part <- with(additive.fit, row + overall)
Col.Part <- additive.fit$col 
plot2way(Row.Part, Col.Part,
         dimnames(attendance)[[1]], 
         dimnames(attendance)[[2]])
```


First, note that the highest intersection is November in 1993 (left upper corner). The lowest intersection is July in 1996 (right lower corner).

Second, there are larger two red rectangulars between June and July. 

Third, we can see that the rectangular region is just slightly rotated off the vertical so the more critical dimension of fit is the month of the year.

Checking stemplot for residuals
```{r}
aplpack::stem.leaf(c(additive.fit$residual))
```

There is a cluster between -0.0004 and 0.0003.

There is one lower deviasion which is 0.0053192703384041 which is in November in 1993.

